<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Boyi Li on The AI Talks</title>
    <link>http://theaitalks.org/authors/boyi-li/</link>
    <description>Recent content in Boyi Li on The AI Talks</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Thu, 08 Jun 2023 00:00:00 +0000</lastBuildDate><atom:link href="http://theaitalks.org/authors/boyi-li/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Learning from Language Models for Visual Intelligence</title>
      <link>http://theaitalks.org/talks/2023/0608/</link>
      <pubDate>Thu, 08 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/talks/2023/0608/</guid>
      <description>Speaker Boyi Li is a Research Scientist at NVIDIA Research and a Postdoctoral Scholar at Berkeley AI Research. Her research interest is in computer vision and machine learning. Her research primarily focuses on multimodal and data-efficient machine learning for building various intelligent systems.
Homepage: https://sites.google.com/site/boyilics/home
Abstract The computer vision community has embraced specialized models trained on fixed object categories like ImageNet or COCO. However, relying solely on visual knowledge may limit flexibility and generality, requiring additional labeled data and hindering user interaction.</description>
    </item>
    
  </channel>
</rss>
