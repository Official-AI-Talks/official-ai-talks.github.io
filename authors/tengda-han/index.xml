<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tengda Han on The AI Talks</title>
    <link>http://theaitalks.org/authors/tengda-han/</link>
    <description>Recent content in Tengda Han on The AI Talks</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Thu, 21 Dec 2023 00:00:00 +0000</lastBuildDate><atom:link href="http://theaitalks.org/authors/tengda-han/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Long video understanding with minimal supervision</title>
      <link>http://theaitalks.org/talks/2023/1221/</link>
      <pubDate>Thu, 21 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/talks/2023/1221/</guid>
      <description>Speaker Tengda Han is a post-doctoral research fellow at the Visual Geometry Group at the University of Oxford. He obtained his PhD from the same group in 2022 supervised by Andrew Zisserman. His current research focuses on self-supervised learning, efficient learning, and video understanding.
Abstract Understanding long videos is one of the pinnacles in computer vision. The long-time axis introduces extra challenges compared with images or short videos, and exhaustive manual annotation on long videos is infeasible.</description>
    </item>
    
  </channel>
</rss>
