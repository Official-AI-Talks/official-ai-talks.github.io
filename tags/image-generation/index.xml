<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>image generation on The AI Talks</title>
    <link>http://theaitalks.org/tags/image-generation/</link>
    <description>Recent content in image generation on The AI Talks</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Thu, 09 Feb 2023 00:00:00 +0000</lastBuildDate><atom:link href="http://theaitalks.org/tags/image-generation/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Personalizing Text-to-image Generation</title>
      <link>http://theaitalks.org/talks/2023/0209/</link>
      <pubDate>Thu, 09 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/talks/2023/0209/</guid>
      <description>Speaker Rinon Gal is a Ph.D. student at Tel Aviv University where he is supervised by Prof. Daniel Cohen-Or and Dr. Amit Bermano. His research focuses on generative models, few-shot and unsupervised approaches, and on combining vision and language. Recently, Rinon has been interning at NVIDIA Research, where he is working on personalization of vision and language models.
Homepage: https://rinongal.github.io
Abstract Text-to-image models offer unprecedented freedom to guide creation through natural language.</description>
    </item>
    
    <item>
      <title>StyleGAN-Based Portrait Image and Video Style Transfer</title>
      <link>http://theaitalks.org/talks/2022/1201/</link>
      <pubDate>Thu, 01 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/talks/2022/1201/</guid>
      <description>Speaker Shuai Yang received the B.S. and Ph.D. degrees (Hons.) in computer science from Peking University, Beijing, China, in 2015 and 2020, respectively. He is currently a postdoctoral research fellow with the S-Lab, Nanyang Technological University. Dr. Yang was a Visiting Scholar with the Texas A&amp;amp;M University, from Sep. 2018 to Sep. 2019. He was a Visiting Student with the National Institute of Informatics, Japan, from Mar. 2017 to Aug.</description>
    </item>
    
    <item>
      <title>Bit Diffusion: Generating Discrete Data using Diffusion Models with Analog Bits and Self-Conditioning</title>
      <link>http://theaitalks.org/talks/2022/0929/</link>
      <pubDate>Thu, 29 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/talks/2022/0929/</guid>
      <description>Speaker Bio: Ting Chen is a research scientist in the Google Brain team. His current research interests include self-supervised representation learning, generative modeling, efficient architectures and generalist learning principles. Before joining Google, he received his Ph.D. in Computer Science from UCLA.
Homepage: https://scholar.google.com/citations?user=KoXUMbsAAAAJ&amp;amp;hl=en.
Abstract We present Bit Diffusion: a simple and generic approach for generating discrete data with continuous diffusion models. The main idea behind our approach is to first represent the discrete data as binary bits, and then train a continuous diffusion model to model these bits as real numbers which we call analog bits.</description>
    </item>
    
  </channel>
</rss>
