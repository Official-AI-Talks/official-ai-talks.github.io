<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>computer vision on The AI Talks</title>
    <link>http://theaitalks.org/tags/computer-vision/</link>
    <description>Recent content in computer vision on The AI Talks</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Thu, 13 Oct 2022 00:00:00 +0000</lastBuildDate><atom:link href="http://theaitalks.org/tags/computer-vision/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Finetuning Vision Models: Improving Robustness and Accuracy</title>
      <link>http://theaitalks.org/talks/2022/1013/</link>
      <pubDate>Thu, 13 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/talks/2022/1013/</guid>
      <description>Speaker Bio: Mitchell is a fourth year PhD student at the University of Washington. His research interests include large models, transfer learning, and robustness.
Homepage: https://mitchellnw.github.io/.
Abstract I&amp;rsquo;ll discuss methods for fine-tuning which improve model robustness and accuracy. These methods leverage the observation that fine-tuned models often appear to lie in a single low error region. To improve robustness, we therefore interpolate the weights of the pre-trained and fine-tuned models.</description>
    </item>
    
    <item>
      <title>Architectures and Training for Visual Understanding</title>
      <link>http://theaitalks.org/talks/2022/1006/</link>
      <pubDate>Thu, 06 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/talks/2022/1006/</guid>
      <description>Speaker Bio: Hugo Touvron is a research scientist at Meta AI Research. During his PhD he was advised by Hervé Jégou and Matthieu Cord. His current research interests include image classification, transfer learning &amp;amp; fine-grained recognition, with an emphasis on the interplay between architectures and training procedures.
Homepage: https://scholar.google.com/citations?user=xImarzoAAAAJ&amp;amp;hl=en
Abstract Deep learning success is often associated with emblematic architectures. Almost everyone has heard of AlexNet, ResNet or GPT. These successes were also powered by well designed optimisation procedures, which are not usually central to the discussion.</description>
    </item>
    
    <item>
      <title>Large-Scale Visual Representation Learning with Vision Transformers</title>
      <link>http://theaitalks.org/talks/2022/0922/</link>
      <pubDate>Thu, 22 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/talks/2022/0922/</guid>
      <description>Speaker Bio: Xiaohua Zhai is a staff researcher and a manager in the Google Research, Brain team, Zürich. He received his PhD degree from Peking University in 2014. His research interests include large-scale representation learning, multimodal learning, transfer learning and self-supervised learning.
Homepage: https://sites.google.com/view/xzhai.
Abstract Attention-based neural networks such as Vision Transformers (ViT) [1] have recently achieved state-of-the-art results on many computer vision benchmarks (e.g. the Visual Task Adaptation Benchmark [2]).</description>
    </item>
    
    <item>
      <title>A Vision-and-Language Approach to Computer Vision in the Wild: Modeling &amp; Benchmark</title>
      <link>http://theaitalks.org/talks/2022/0908/</link>
      <pubDate>Thu, 08 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/talks/2022/0908/</guid>
      <description>Speaker Bio: Chunyuan Li is currently a Principal Researcher in the Deep Learning Team at Microsoft Research, Redmond. Before that, Chunyuan obtained his PhD at Duke University, working on probabilistic deep learning. He also spent time with Uber AI, Adobe Research, NIST and INRIA. At MSR, Chunyuan is mainly working on large-scale pre-training in computer vision (CV) and vision-language multimodality (MM), with a focus on building transferable vision models that can effortlessly generalize to a wide range of downstream CV &amp;amp; MM tasks.</description>
    </item>
    
  </channel>
</rss>
