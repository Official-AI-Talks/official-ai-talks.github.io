<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>foundation models on The AI Talks</title>
    <link>http://theaitalks.org/tags/foundation-models/</link>
    <description>Recent content in foundation models on The AI Talks</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Thu, 22 Sep 2022 00:00:00 +0000</lastBuildDate><atom:link href="http://theaitalks.org/tags/foundation-models/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Large-Scale Visual Representation Learning with Vision Transformers</title>
      <link>http://theaitalks.org/talks/2022/0922/</link>
      <pubDate>Thu, 22 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/talks/2022/0922/</guid>
      <description>Speaker Bio: Xiaohua Zhai is a staff researcher and a manager in the Google Research, Brain team, ZÃ¼rich. He received his PhD degree from Peking University in 2014. His research interests include large-scale representation learning, multimodal learning, transfer learning and self-supervised learning.
Homepage: https://sites.google.com/view/xzhai.
Abstract Attention-based neural networks such as Vision Transformers (ViT) [1] have recently achieved state-of-the-art results on many computer vision benchmarks (e.g. the Visual Task Adaptation Benchmark [2]).</description>
    </item>
    
    <item>
      <title>A Vision-and-Language Approach to Computer Vision in the Wild: Modeling &amp; Benchmark</title>
      <link>http://theaitalks.org/talks/2022/0908/</link>
      <pubDate>Thu, 08 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/talks/2022/0908/</guid>
      <description>Speaker Bio: Chunyuan Li is currently a Principal Researcher in the Deep Learning Team at Microsoft Research, Redmond. Before that, Chunyuan obtained his PhD at Duke University, working on probabilistic deep learning. He also spent time with Uber AI, Adobe Research, NIST and INRIA. At MSR, Chunyuan is mainly working on large-scale pre-training in computer vision (CV) and vision-language multimodality (MM), with a focus on building transferable vision models that can effortlessly generalize to a wide range of downstream CV &amp;amp; MM tasks.</description>
    </item>
    
  </channel>
</rss>
