<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>generative modeling on The AI Talks</title>
    <link>http://theaitalks.org/tags/generative-modeling/</link>
    <description>Recent content in generative modeling on The AI Talks</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Thu, 29 Sep 2022 00:00:00 +0000</lastBuildDate><atom:link href="http://theaitalks.org/tags/generative-modeling/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Bit Diffusion: Generating Discrete Data using Diffusion Models with Analog Bits and Self-Conditioning</title>
      <link>http://theaitalks.org/talks/2022/0929/</link>
      <pubDate>Thu, 29 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/talks/2022/0929/</guid>
      <description>Speaker Bio: Ting Chen is a research scientist in the Google Brain team. His current research interests include self-supervised representation learning, generative modeling, efficient architectures and generalist learning principles. Before joining Google, he received his Ph.D. in Computer Science from UCLA.
Homepage: https://scholar.google.com/citations?user=KoXUMbsAAAAJ&amp;amp;hl=en.
Abstract We present Bit Diffusion: a simple and generic approach for generating discrete data with continuous diffusion models. The main idea behind our approach is to first represent the discrete data as binary bits, and then train a continuous diffusion model to model these bits as real numbers which we call analog bits.</description>
    </item>
    
  </channel>
</rss>
