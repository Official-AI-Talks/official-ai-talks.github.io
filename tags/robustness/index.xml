<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>robustness on The AI Talks</title>
    <link>http://theaitalks.org/tags/robustness/</link>
    <description>Recent content in robustness on The AI Talks</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Wed, 07 Dec 2022 00:00:00 +0000</lastBuildDate><atom:link href="http://theaitalks.org/tags/robustness/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Improving Robustness to Distribution Shifts: Methods and Benchmarks</title>
      <link>http://theaitalks.org/talks/2022/1207/</link>
      <pubDate>Wed, 07 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/talks/2022/1207/</guid>
      <description>Speaker Shiori Sagawa is a fourth-year PhD student at Stanford University, advised by Percy Liang. She studies robustness to distribution shifts, and to this end, she has developed methods based on distributionally robust optimization, analyzed these algorithms in the context of deep learning models, and recently built a benchmark on distribution shifts in the wild. She is an Apple PhD Scholar in AI/ML.
Homepage: https://cs.stanford.edu/~ssagawa/.
Abstract Machine learning models deployed in the real world constantly face distribution shifts, yet current models are not robust to these shifts; they can perform well when the train and test distributions are identical, but still have their performance plummet when evaluated on a different test distribution.</description>
    </item>
    
    <item>
      <title>Finetuning Vision Models: Improving Robustness and Accuracy</title>
      <link>http://theaitalks.org/talks/2022/1013/</link>
      <pubDate>Thu, 13 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/talks/2022/1013/</guid>
      <description>Speaker Bio: Mitchell is a fourth year PhD student at the University of Washington. His research interests include large models, transfer learning, and robustness.
Homepage: https://mitchellnw.github.io/.
Abstract I&amp;rsquo;ll discuss methods for fine-tuning which improve model robustness and accuracy. These methods leverage the observation that fine-tuned models often appear to lie in a single low error region. To improve robustness, we therefore interpolate the weights of the pre-trained and fine-tuned models.</description>
    </item>
    
  </channel>
</rss>
