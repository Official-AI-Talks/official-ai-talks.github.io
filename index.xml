<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>The AI Talks</title>
    <link>http://theaitalks.org/</link>
    <description>Recent content on The AI Talks</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Thu, 09 Feb 2023 00:00:00 +0000</lastBuildDate><atom:link href="http://theaitalks.org/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Personalizing Text-to-image Generation</title>
      <link>http://theaitalks.org/talks/2023/0209/</link>
      <pubDate>Thu, 09 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/talks/2023/0209/</guid>
      <description>Speaker Rinon Gal is a Ph.D. student at Tel Aviv University where he is supervised by Prof. Daniel Cohen-Or and Dr. Amit Bermano. His research focuses on generative models, few-shot and unsupervised approaches, and on combining vision and language. Recently, Rinon has been interning at NVIDIA Research, where he is working on personalization of vision and language models.
Homepage: https://rinongal.github.io
Abstract Text-to-image models offer unprecedented freedom to guide creation through natural language.</description>
    </item>
    
    <item>
      <title>Improving Robustness to Distribution Shifts: Methods and Benchmarks</title>
      <link>http://theaitalks.org/talks/2022/1207/</link>
      <pubDate>Wed, 07 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/talks/2022/1207/</guid>
      <description>Speaker Shiori Sagawa is a fourth-year PhD student at Stanford University, advised by Percy Liang. She studies robustness to distribution shifts, and to this end, she has developed methods based on distributionally robust optimization, analyzed these algorithms in the context of deep learning models, and recently built a benchmark on distribution shifts in the wild. She is an Apple PhD Scholar in AI/ML.
Homepage: https://cs.stanford.edu/~ssagawa/.
Abstract Machine learning models deployed in the real world constantly face distribution shifts, yet current models are not robust to these shifts; they can perform well when the train and test distributions are identical, but still have their performance plummet when evaluated on a different test distribution.</description>
    </item>
    
    <item>
      <title>StyleGAN-Based Portrait Image and Video Style Transfer</title>
      <link>http://theaitalks.org/talks/2022/1201/</link>
      <pubDate>Thu, 01 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/talks/2022/1201/</guid>
      <description>Speaker Shuai Yang received the B.S. and Ph.D. degrees (Hons.) in computer science from Peking University, Beijing, China, in 2015 and 2020, respectively. He is currently a postdoctoral research fellow with the S-Lab, Nanyang Technological University. Dr. Yang was a Visiting Scholar with the Texas A&amp;amp;M University, from Sep. 2018 to Sep. 2019. He was a Visiting Student with the National Institute of Informatics, Japan, from Mar. 2017 to Aug.</description>
    </item>
    
    <item>
      <title>Principled Solutions for Efficient Artificial Neural Networks</title>
      <link>http://theaitalks.org/talks/2022/1124/</link>
      <pubDate>Thu, 24 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/talks/2022/1124/</guid>
      <description>Speaker Bio: Adrian Bulat is currently a Senior Research Scientist at Samsung AI Cambridge. Previously, he received his PhD from the University of Nottingham as part of the Computer Vision Laboratory group. His research work lies at the intersection of Computer Vision and Machine Learning, with work conducted on topics such as efficient neural networks (via bit quantization, network binarization and compression), representation learning and human analysis, where he covered topics such face alignment, face super-resolution and human pose estimation.</description>
    </item>
    
    <item>
      <title>Prompting-based Continual Learning</title>
      <link>http://theaitalks.org/talks/2022/1117/</link>
      <pubDate>Thu, 17 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/talks/2022/1117/</guid>
      <description>Speaker Bio: Zifeng Wang is a Ph.D. student at Northeastern University. He received his B.S. degree in Electronic Engineering from Tsinghua University. His research interests include continual (lifelong) learning, data-efficient and parameter-efficient learning, adversarial robustness, and real-world machine learning applications.
Homepage: https://kingspencer.github.io/.
Abstract The mainstream paradigm behind continual learning has been to adapt the model parameters to non-stationary data distributions, where catastrophic forgetting is the central challenge. In this talk, we present a new continual learning paradigm – Prompting-based Continual Learning, which learns a tiny set of parameters, called prompts, to properly instruct a pre-trained model to learn tasks arriving sequentially.</description>
    </item>
    
    <item>
      <title>Finetuning Vision Models: Improving Robustness and Accuracy</title>
      <link>http://theaitalks.org/talks/2022/1013/</link>
      <pubDate>Thu, 13 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/talks/2022/1013/</guid>
      <description>Speaker Bio: Mitchell is a fourth year PhD student at the University of Washington. His research interests include large models, transfer learning, and robustness.
Homepage: https://mitchellnw.github.io/.
Abstract I&amp;rsquo;ll discuss methods for fine-tuning which improve model robustness and accuracy. These methods leverage the observation that fine-tuned models often appear to lie in a single low error region. To improve robustness, we therefore interpolate the weights of the pre-trained and fine-tuned models.</description>
    </item>
    
    <item>
      <title>Architectures and Training for Visual Understanding</title>
      <link>http://theaitalks.org/talks/2022/1006/</link>
      <pubDate>Thu, 06 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/talks/2022/1006/</guid>
      <description>Speaker Bio: Hugo Touvron is a research scientist at Meta AI Research. During his PhD he was advised by Hervé Jégou and Matthieu Cord. His current research interests include image classification, transfer learning &amp;amp; fine-grained recognition, with an emphasis on the interplay between architectures and training procedures.
Homepage: https://scholar.google.com/citations?user=xImarzoAAAAJ&amp;amp;hl=en
Abstract Deep learning success is often associated with emblematic architectures. Almost everyone has heard of AlexNet, ResNet or GPT. These successes were also powered by well designed optimisation procedures, which are not usually central to the discussion.</description>
    </item>
    
    <item>
      <title>Speakers</title>
      <link>http://theaitalks.org/speakers/</link>
      <pubDate>Fri, 30 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/speakers/</guid>
      <description>Chunyuan Li Microsoft
Yuzhe Yang MIT
Xiaohua Zhai Google
Zongyuan Ge Monash University
Ting Chen Google
Hugo Touvron Meta
Mitchell Wortsman University of Washington
Zifeng Wang Northeastern University
Adrian Bulat Samsung AI Cambridge
Shuai Yang NTU Singapore
Shiori Sagawa Stanford
Rinon Gal Tel-Aviv University</description>
    </item>
    
    <item>
      <title>Bit Diffusion: Generating Discrete Data using Diffusion Models with Analog Bits and Self-Conditioning</title>
      <link>http://theaitalks.org/talks/2022/0929/</link>
      <pubDate>Thu, 29 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/talks/2022/0929/</guid>
      <description>Speaker Bio: Ting Chen is a research scientist in the Google Brain team. His current research interests include self-supervised representation learning, generative modeling, efficient architectures and generalist learning principles. Before joining Google, he received his Ph.D. in Computer Science from UCLA.
Homepage: https://scholar.google.com/citations?user=KoXUMbsAAAAJ&amp;amp;hl=en.
Abstract We present Bit Diffusion: a simple and generic approach for generating discrete data with continuous diffusion models. The main idea behind our approach is to first represent the discrete data as binary bits, and then train a continuous diffusion model to model these bits as real numbers which we call analog bits.</description>
    </item>
    
    <item>
      <title>MMAI: Close the loop for Medical AI application</title>
      <link>http://theaitalks.org/talks/2022/0923/</link>
      <pubDate>Fri, 23 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/talks/2022/0923/</guid>
      <description>Speaker Bio: Associate Professor Zongyuan Ge conducts interdisciplinary research at the boundary between medical artificial intelligence, computer-aided diagnosis, biomedical engineering, medical imaging and machine learning and is a multi-award winning medical information science and technology entrepreneur. His research leverages cutting-edge AI technologies using large-scale multi-modality medical data including imaging, medical records, gene data and models the clinicians’ medical knowledge underlying tasks like diagnosis, prognosis and treatment for eye (ophthalmology), skin (dermatology), heart (cardiovascular) and neurodegeneration diseases such as epilepsy and multiple sclerosis.</description>
    </item>
    
    <item>
      <title>Large-Scale Visual Representation Learning with Vision Transformers</title>
      <link>http://theaitalks.org/talks/2022/0922/</link>
      <pubDate>Thu, 22 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/talks/2022/0922/</guid>
      <description>Speaker Bio: Xiaohua Zhai is a staff researcher and a manager in the Google Research, Brain team, Zürich. He received his PhD degree from Peking University in 2014. His research interests include large-scale representation learning, multimodal learning, transfer learning and self-supervised learning.
Homepage: https://sites.google.com/view/xzhai.
Abstract Attention-based neural networks such as Vision Transformers (ViT) [1] have recently achieved state-of-the-art results on many computer vision benchmarks (e.g. the Visual Task Adaptation Benchmark [2]).</description>
    </item>
    
    <item>
      <title>Using AI to Diagnose and Assess Parkinson&#39;s Disease: Challenges, Algorithms, and Applications</title>
      <link>http://theaitalks.org/talks/2022/0915/</link>
      <pubDate>Thu, 15 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/talks/2022/0915/</guid>
      <description>Speaker Bio: Yuzhe Yang is a PhD student in computer science at MIT CSAIL. He received his B.S. degree in EECS at Peking University. His research interests include machine learning and AI for healthcare. His research focuses on fundamental machine learning algorithms for model robustness and generalization to enable real-world applications especially in health domain, as well as building innovative learning systems to enable new modalities and frameworks for digital health.</description>
    </item>
    
    <item>
      <title>A Vision-and-Language Approach to Computer Vision in the Wild: Modeling &amp; Benchmark</title>
      <link>http://theaitalks.org/talks/2022/0908/</link>
      <pubDate>Thu, 08 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/talks/2022/0908/</guid>
      <description>Speaker Bio: Chunyuan Li is currently a Principal Researcher in the Deep Learning Team at Microsoft Research, Redmond. Before that, Chunyuan obtained his PhD at Duke University, working on probabilistic deep learning. He also spent time with Uber AI, Adobe Research, NIST and INRIA. At MSR, Chunyuan is mainly working on large-scale pre-training in computer vision (CV) and vision-language multimodality (MM), with a focus on building transferable vision models that can effortlessly generalize to a wide range of downstream CV &amp;amp; MM tasks.</description>
    </item>
    
    <item>
      <title>Contact</title>
      <link>http://theaitalks.org/contact/</link>
      <pubDate>Thu, 18 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/contact/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>Subscribe</title>
      <link>http://theaitalks.org/subscribe/</link>
      <pubDate>Tue, 19 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/subscribe/</guid>
      <description>Please subscribe to our newsletter to receive the latest updates.</description>
    </item>
    
    <item>
      <title>About</title>
      <link>http://theaitalks.org/about/</link>
      <pubDate>Mon, 18 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/about/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>Organizers</title>
      <link>http://theaitalks.org/organizers/</link>
      <pubDate>Mon, 18 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/organizers/</guid>
      <description>Kaiyang Zhou NTU, Singapore
Jingkang Yang NTU, Singapore
Ziqi Huang NTU, Singapore
Yuanhan Zhang NTU, Singapore
Bo Li NTU, Singapore
Qinghong Lin NUS, Singapore
Zheng Shou NUS, Singapore
Ziwei Liu NTU, Singapore
Chen Change Loy NTU, Singapore</description>
    </item>
    
  </channel>
</rss>
